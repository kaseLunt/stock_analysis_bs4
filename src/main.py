import logging
import pandas as pd
import os

from extract.data_extraction import fetch_all_data_for_stocks
from transform.data_transformation import transform_data 

# Initialize logging for debugging and tracking
logging.basicConfig(level=logging.INFO)

# Get the directory of the currently executing script
dir_path = os.path.dirname(os.path.realpath(__file__))
stock_data_path = os.path.join(dir_path, '../stock_data.csv')

# Main orchestration function
def run_etl_analysis():
    """Main function to run the entire ETL process: data extraction and transformation."""
    
    # Step 1: Data Extraction
    logging.info("Starting data extraction process.")
    fetch_all_data_for_stocks()
    logging.info("Data extraction complete.")

    # Step 2: Data Transformation
    logging.info("Starting data transformation process.")

    
    # Read the raw stock data from the CSV file generated by data_extraction
    stock_data_df = pd.read_csv(stock_data_path)
    
    # Transform the data using the imported transform_data function
    transformed_stock_data_df = transform_data(stock_data_df)
    
    logging.info("Data transformation complete.")
    print(transformed_stock_data_df)

# Entry point of the script
if __name__ == "__main__":
    run_etl_analysis()